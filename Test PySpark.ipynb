{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import csv\n",
    "\n",
    "import datetime as dt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'segmentid_fiscalyear_dummy.csv'\n",
    "\n",
    "# to skip header\n",
    "data = sc.textFile(file)\n",
    "header = data.first()\n",
    "\n",
    "res = sc.textFile(file) \\\n",
    "        .filter(lambda x: x != header) \\\n",
    "        .mapPartitions(lambda x: csv.reader(x)) \\\n",
    "        .map(lambda x: ((x[0], dt.datetime.strptime(x[1], '%m/%d/%Y').year), 1)) \\\n",
    "        .reduceByKey(lambda x, y: x + y) \\\n",
    "        .sortByKey(True, 1) \\\n",
    "        .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1000', 2018), 2),\n",
       " (('1000', 2019), 3),\n",
       " (('2000', 2016), 1),\n",
       " (('2000', 2017), 2),\n",
       " (('3000', 2016), 1),\n",
       " (('3000', 2017), 2),\n",
       " (('3000', 2018), 3),\n",
       " (('4000', 2017), 3),\n",
       " (('4000', 2018), 2),\n",
       " (('4000', 2019), 1)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols(data):\n",
    "    \"\"\" data = [(x1, y1), ..., (xi, yi), ..., (xN, yN)] \"\"\"\n",
    "    x_bar = sum([d[0] for d in data])/len(data)\n",
    "    y_bar = sum([d[1] for d in data])/len(data)\n",
    "    numerator = sum([(d[0] - x_bar)*(d[1] - y_bar) for d in data])\n",
    "    denomenator = sum([(d[0] - x_bar)**2 for d in data])\n",
    "    return numerator/denomenator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-100.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(2015, 100), (2016, 200), (2017, 300), (2018, 400), (2019, 500)]\n",
    "ols(data)\n",
    "data = [(2015, 500), (2016, 400), (2017, 300), (2018, 200), (2019, 100)]\n",
    "ols(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1000', (2018, 2)),\n",
       " ('1000', (2019, 3)),\n",
       " ('2000', (2016, 1)),\n",
       " ('2000', (2017, 2)),\n",
       " ('3000', (2016, 1)),\n",
       " ('3000', (2017, 2)),\n",
       " ('3000', (2018, 3)),\n",
       " ('4000', (2017, 3)),\n",
       " ('4000', (2018, 2)),\n",
       " ('4000', (2019, 1))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return coefficient \n",
    "sc.textFile(file) \\\n",
    "  .filter(lambda x: x != header) \\\n",
    "  .mapPartitions(lambda x: csv.reader(x)) \\\n",
    "  .map(lambda x: ((x[0], dt.datetime.strptime(x[1], '%m/%d/%Y').year), 1)) \\\n",
    "  .reduceByKey(lambda x, y: x + y) \\\n",
    "  .sortByKey(True, 1) \\\n",
    "  .map(lambda x: (x[0][0], (x[0][1], x[1]))) \\\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1000', 1.0), ('2000', 1.0), ('3000', 1.0), ('4000', -1.0)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'segmentid_fiscalyear_dummy.csv'\n",
    "\n",
    "# to skip header\n",
    "data = sc.textFile(file)\n",
    "header = data.first()\n",
    "\n",
    "# return coefficient \n",
    "sc.textFile(file) \\\n",
    "  .filter(lambda x: x != header) \\\n",
    "  .mapPartitions(lambda x: csv.reader(x)) \\\n",
    "  .map(lambda x: ((x[0], dt.datetime.strptime(x[1], '%m/%d/%Y').year), 1)) \\\n",
    "  .reduceByKey(lambda x, y: x + y) \\\n",
    "  .sortByKey(True, 1) \\\n",
    "  .map(lambda x: (x[0][0], [(x[0][1], x[1])])) \\\n",
    "  .reduceByKey(lambda x, y: x + y) \\\n",
    "  .mapValues(lambda x: ols(x)) \\\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1000', [(2018, 2), (2019, 3), ('OLS_COEF', 1.0)]),\n",
       " ('2000', [(2016, 1), (2017, 2), ('OLS_COEF', 1.0)]),\n",
       " ('3000', [(2016, 1), (2017, 2), (2018, 3), ('OLS_COEF', 1.0)]),\n",
       " ('4000', [(2017, 3), (2018, 2), (2019, 1), ('OLS_COEF', -1.0)])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'segmentid_fiscalyear_dummy.csv'\n",
    "\n",
    "# to skip header\n",
    "data = sc.textFile(file)\n",
    "header = data.first()\n",
    "\n",
    "# return coefficient \n",
    "sc.textFile(file) \\\n",
    "  .filter(lambda x: x != header) \\\n",
    "  .mapPartitions(lambda x: csv.reader(x)) \\\n",
    "  .map(lambda x: ((x[0], dt.datetime.strptime(x[1], '%m/%d/%Y').year), 1)) \\\n",
    "  .reduceByKey(lambda x, y: x + y) \\\n",
    "  .sortByKey(True, 1) \\\n",
    "  .map(lambda x: (x[0][0], [(x[0][1], x[1])])) \\\n",
    "  .reduceByKey(lambda x, y: x + y) \\\n",
    "  .mapValues(lambda x: x + [('OLS_COEF', ols(x))]) \\\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_zer0(row):\n",
    "    expected = {2015: 0, 2016:0, 2017:0, 2018:0, 2019:0}\n",
    "    for x in row:\n",
    "        expected[x[0]] += x[1]\n",
    "    expected = [(k, v) for k, v in expected.items()]\n",
    "    return expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2015, 0), (2016, 0), (2017, 0), (2018, 2), (2019, 3)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(2018, 2), (2019, 3)]\n",
    "fill_zer0(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1000',\n",
       "  [(2015, 0), (2016, 0), (2017, 0), (2018, 2), (2019, 3), ('OLS_COEF', 1.0)]),\n",
       " ('2000',\n",
       "  [(2015, 0), (2016, 1), (2017, 2), (2018, 0), (2019, 0), ('OLS_COEF', 1.0)]),\n",
       " ('3000',\n",
       "  [(2015, 0), (2016, 1), (2017, 2), (2018, 3), (2019, 0), ('OLS_COEF', 1.0)]),\n",
       " ('4000',\n",
       "  [(2015, 0), (2016, 0), (2017, 3), (2018, 2), (2019, 1), ('OLS_COEF', -1.0)])]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'segmentid_fiscalyear_dummy.csv'\n",
    "\n",
    "# to skip header\n",
    "data = sc.textFile(file)\n",
    "header = data.first()\n",
    "\n",
    "# return coefficient \n",
    "sc.textFile(file) \\\n",
    "  .filter(lambda x: x != header) \\\n",
    "  .mapPartitions(lambda x: csv.reader(x)) \\\n",
    "  .map(lambda x: ((x[0], dt.datetime.strptime(x[1], '%m/%d/%Y').year), 1)) \\\n",
    "  .reduceByKey(lambda x, y: x + y) \\\n",
    "  .sortByKey(True, 1) \\\n",
    "  .map(lambda x: (x[0][0], [(x[0][1], x[1])])) \\\n",
    "  .reduceByKey(lambda x, y: x + y) \\\n",
    "  .mapValues(lambda x: fill_zer0(x) + [('OLS_COEF', ols(x))]) \\\n",
    "  .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
